#Cell[1]:
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.datasets import fetch_lfw_people
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neural_network import MLPClassifier
import numpy as np
import os,cv2
def plot_gallery(images, titles, h, w, n_row=3, n_col=4):
    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))
    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)
    for i in range(n_row * n_col):
        plt.subplot(n_row, n_col, i + 1)
        plt.imshow(images[i].reshape((h,w)), cmap=plt.cm.gray)
        plt.title(titles[i], size=12)
        plt.xticks(())
        plt.yticks(())

#Cell[2]:
dir_name = "images/train/"
y=[];x=[];target_names=[]
person_id=0;h=w=300
n_samples=0
class_names=[]
for person_name in os.listdir(dir_name):
    dir_path = dir_name+person_name+"/"
    class_names.append(person_name)
    for image_name in os.listdir(dir_path):
        image_path = dir_path+image_name
        img = cv2.imread(image_path)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        resized_image= cv2.resize(gray,(h,w))
        v = resized_image.flatten()
        x.append(v)
        n_samples =n_samples+1
        y.append(person_id)
        target_names.append(person_name)
    person_id=person_id+1
y=np.array(y)
x=np.array(x)
target_names =np.array(target_names)
n_features = x.shape[1]
print(y.shape,x.shape,target_names.shape)
print("Number of samples:",n_samples)
n_classes = target_names.shape[0]
print("Total dataset size:")
print("n_samples: %d" % n_samples)
print("n_features: %d" % n_features)
print("n_classes: %d" % n_classes)

#Cell[3]:
from sklearn.datasets import fetch_lfw_people
from sklearn.model_selection import train_test_split
# Load dataset
lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)
x = lfw_people.data
y = lfw_people.target
# Verify dataset size
if x.shape[0] == 0 or y.shape[0] == 0:
    raise ValueError("Dataset is empty. Check your data loading process.")
# Split dataset
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)
print(f"Training set size: {x_train.shape}, Test set size: {x_test.shape}")

#Cell[4]:
# Ensure correct image dimensions
h, w = lfw_people.images.shape[1], lfw_people.images.shape[2]  # Get height and width
print(f"Image dimensions: {h}x{w}")
# Fit PCA
pca = PCA(n_components=n_components, svd_solver='randomized', whiten=True).fit(x_train)
# Reshape the PCA components into images
eigenfaces = pca.components_.reshape((n_components, h, w))
# Titles for eigenfaces
eigenfaces_titles = ["eigenface %d" % i for i in range(eigenfaces.shape[0])]
# Plot gallery of eigenfaces (assuming plot_gallery is defined)
plot_gallery(eigenfaces, eigenfaces_titles, h, w)
plt.show()

#Cell[5]:
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)
n_components = 150
print("Extracting the top %d eigenfaces from %d faces"% (n_components, x_train.shape[0]))
pca = PCA(n_components=n_components, svd_solver='randomized', whiten=True).fit(x_train)
eigenfaces = pca.components_.reshape((n_components, h, w))
eigenfaces_titles = ["eigenface %d" % i for i in range(eigenfaces.shape[0])]
plot_gallery(eigenfaces, eigenfaces_titles, h, w)
plt.show()
print("Projecting the input data on the eigenfaces orthonormal basis")
x_train_pca = pca.transform(x_train)
x_test_pca = pca.transform(x_test)
print(x_train_pca.shape,x_test_pca.shape)
lda = LinearDiscriminantAnalysis()
lda.fit(x_train_pca, y_train)
x_train_lda = lda.transform(x_train_pca)
x_test_lda = lda.transform(x_test_pca)
print("Project done...")

#Cell[6]:
clf = MLPClassifier(random_state=1, hidden_layer_sizes=(10,10), max_iter=1000, verbose=True).fit(x_train_lda, y_train)
print("Model weights:")
model_info = [coef.shape for coef in clf.coefs_]
print(model_info)

#Cell[7]:
import numpy as np
import matplotlib.pyplot as plt
y_pred = []
y_prob = []
# Filter valid indices
valid_indices = [i for i in range(len(y_test)) if 0 <= y_test[i] < len(class_names)]
if len(valid_indices) != len(y_test):
    print(f"Warning: {len(y_test) - len(valid_indices)} invalid indices in y_test were removed.")
y_test = y_test[valid_indices]
x_test = x_test[valid_indices]
x_test_lda = x_test_lda[valid_indices]
# Predict probabilities and classes for test data
for test_face in x_test_lda:
    prob = clf.predict_proba([test_face])[0]
    class_id = np.argmax(prob)  # Get the class with the highest probability
    y_pred.append(class_id)
    y_prob.append(np.max(prob))
y_pred = np.array(y_pred)
# Validate predicted class IDs
if not all(0 <= pred < len(class_names) for pred in y_pred):
    print("Warning: Some predictions are out of range for class_names.")
    y_pred = [pred if 0 <= pred < len(class_names) else -1 for pred in y_pred]
    y_prob = [prob for pred, prob in zip(y_pred, y_prob) if pred != -1]
    y_pred = [pred for pred in y_pred if pred != -1]
    print("Invalid predictions have been removed.")
# Generate prediction titles and calculate accuracy
prediction_titles = []
true_positive = 0
for i in range(len(y_pred)):
    true_name = class_names[y_test[i]]
    pred_name = class_names[y_pred[i]]
    result = f'pred: {pred_name}, pr: {y_prob[i]:.2f} \ntrue: {true_name}'
    prediction_titles.append(result)
    if true_name == pred_name:
        true_positive += 1
accuracy = (true_positive * 100) / len(y_pred)
print("Accuracy:", accuracy)
# Plot results
plot_gallery(x_test, prediction_titles, h, w)
plt.show()
